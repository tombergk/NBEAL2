{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Variant Filtration Pipeline for *NBEAL2* project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Fastq files\n",
    "\n",
    "All generated fastq files have been deposited to the [NCBI Sequence Read Archive](http://www.ncbi.nlm.nih.gov/sra) (project accession number \\#PRJNA296481)\n",
    "\n",
    "\\#PRJNA296481 encompasses 32 whole exome sequencing experiments from 32 different mice representing 8 ENU suppressor lines: *MF5L*1, *MF5L*5, *MF5L*6, *MF5L*8, *MF5L*9, *MF5L*11, *MF5L*12, *MF5L*16.\n",
    "\n",
    "Current pipeline calls variants jointly from all the 32 sequencing experiments and then focuses on 4 mice from line *MF5L*6: \\#SRR2473222, \\#SRR2473223, \\#SRR2473224, \\#SRR2473338\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Overview of variant calling pipeline\n",
    "\n",
    "Reference genome: Mus_musculus GRCm38 release 73, downloaded from Ensemble\n",
    "\n",
    "**Used software**: \n",
    "* bwa (version 0.7.5a-r405)\n",
    "* picard-tools (version 1.105)\n",
    "* GenomeAnalysisTK (version 2.6.5)\n",
    "\n",
    "**Steps to obtain the .vcf files:**\n",
    "1. bwa aln -q 15\n",
    " bwa sampe\n",
    "2. picard-tools/SortSam.jar SORT_ORDER=coordinate VALIDATION_STRINGENCY=SILENT CREATE_INDEX=true\n",
    "3. picard-tools/MarkDuplicates.jar VALIDATION_STRINGENCY=SILENT REMOVE_DUPLICATES=true ASSUME_SORTED=true CREATE_INDEX=true\n",
    "4. GenomeAnalysisTK/GenomeAnalysisTK.jar -T RealignerTargetCreator\n",
    "5. GenomeAnalysisTK/GenomeAnalysisTK.jar -T IndelRealigner\n",
    "6. picard-tools/FixMateInformation.jar SORT_ORDER=coordinate VALIDATION_STRINGENCY=SILENT CREATE_INDEX=true\n",
    "7. GenomeAnalysisTK/GenomeAnalysisTK.jar -T HaplotypeCaller -stand_call_conf 50.0 stand_emit_conf\n",
    "8. GenomeAnalysisTK/GenomeAnalysisTK.jar -T VariantAnnotator -A VariantType\n",
    "9. GenomeAnalysisTK/GenomeAnalysisTK.jar -T SelectVariants -selectType SNP \n",
    "10. GenomeAnalysisTK/GenomeAnalysisTK.jar -T SelectVariants -selectType INDEL\n",
    "11. GenomeAnalysisTK/GenomeAnalysisTK.jar -T VariantFiltration --variant SNP.vcf --filterExpression 'QD < 2.0 || MQ < 40.0 || FS > 60.0 || HaplotypeScore > 13.0 || MQRankSum < -12.5 || ReadPosRankSum < -8.0' --filterName 'FAIL'\n",
    "12. GenomeAnalysisTK/GenomeAnalysisTK.jar -T VariantFiltration --variant INDEL.vcf --filterExpression \"QD < 2.0 || FS > 200.0 || ReadPosRankSum < -20.0 || InbreedingCoeff < -0.8\" --filterName FAILED\n",
    "\n",
    "_End result is two vcf files: SNP.vcf and INDEL.vcf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Annotation of called SNP.vcf and INDEL.vcf\n",
    "\n",
    "Details on Annovar version and reference sequence:\n",
    "\n",
    "1. $LastChangedDate: 2012-05-25\n",
    "2. annotate_variation.pl --buildver mm10 --downdb seq mousedb/mm10_seq\n",
    "_Downloading annotation database ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz ... OK_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#UNIX commands:\n",
    "    \n",
    "grep '#CHROM' SNP.vcf > header.txt\n",
    "cat SNP.vcf INDEL.vcf | sort -k1n -k2n | grep -v '#' > merged.vcf\n",
    "\n",
    "convert2annovar.pl merged.vcf -format vcf4old -includeinfo > merged\n",
    "annotate_variation.pl merged --buildver mm10 /database/annovar/mousedb/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Preparation of files for filtration\n",
    "\n",
    "###Merge and reformat Annovar output files back into one .vcf\n",
    "\n",
    "Input files are Annovar output files 'merged.exonic_variant_function' and 'merged.variant_function'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import all necessary packages\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "import vcf\n",
    "import subprocess\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reformatAnnovar(FileName,Header):\n",
    "    '''reformatAnnovar will merge .exonic_variant_function and .variant_function\n",
    "    back into one vcf file while adding Annovar Annotation into the INFO column'''\n",
    "    \n",
    "    input1=open(FileName+'.variant_function','r')\n",
    "    input2=open(FileName+'.exonic_variant_function','r')\n",
    "    outfile=open(FileName+'_annot.vcf','w')\n",
    "    header=open(Header,'r').readline().rstrip()\n",
    "    rows=[]\n",
    "    exonic=dict()\n",
    "    \n",
    "    print(header,file=outfile)\n",
    "    \n",
    "    for line in input2:\n",
    "        line=line.strip()\n",
    "        row=line.split('\\t')\n",
    "        row[15]=row[15]+';AnnovarType='+'_'.join(row[1].split())+';AnnovarGene='+'_'.join(row[2].split())\n",
    "        new_line=row[8:len(row)]        \n",
    "        new_line='\\t'.join(new_line)\n",
    "        exonic[row[3]+'_'+row[4]]=new_line\n",
    "\n",
    "    for line in input1:\n",
    "        line=line.strip()\n",
    "        row=line.split('\\t')\n",
    "        \n",
    "        if row[2]+'_'+row[3] in exonic:\n",
    "            print(exonic[row[2]+'_'+row[3]],file=outfile)\n",
    "            continue\n",
    "        else:\n",
    "            row[14]=row[14]+';AnnovarType='+'_'.join(row[0].split())+';AnnovarGene='+'_'.join(row[1].split())\n",
    "            new_line=row[7:len(row)]\n",
    "            print('\\t'.join(new_line),file=outfile)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I merge Annovar annotation files of the original 'merged.vcf' file into **'merged_annot.vcf'** file. 'merged_annot.vcf' file will be used for the downstream filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reformatAnnovar('merged','header.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###Generating a list of known strain specific variation\n",
    "\n",
    "Before filtering, I am creating a dictionary of all known C57BL/6J and 129/SvImJ SNPs necessary for one of the filtering steps! The .vcf files for these SNPs and INDELs (GRCm38) are downloaded from the [Mouse Genomes Project](http://www.sanger.ac.uk/resources/mouse/genomes/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VariantDictionaryFromVcf(VCFfile):\n",
    "    '''This Function Takes the variants in a given VCF file\n",
    "    and returns them in a dictionary formatted as chr_pos as keys'''\n",
    "    input=open(VCFfile)\n",
    "    variants=dict()\n",
    "    for line in input:\n",
    "        if not line.startswith('#'):\n",
    "            row=line.rstrip().split('\\t')\n",
    "            variants[row[0]+'_'+row[1]]=0\n",
    "    \n",
    "    return variants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMJ=VariantDictionaryFromVcf('129_mm10_variants.vcf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant Filtration Pipeline\n",
    "\n",
    "###FILTER 1\n",
    "from 'merged_annot.vcf' to 'merged_annot_filter1.vcf'\n",
    "\n",
    "The goal is to extract heterozygous variants present in the 4 mice from *MF5L*6 suppressor line.\n",
    "\n",
    "|MouseID|SRA Accession|Name in VCF|\n",
    "|-|-|-|\n",
    "|31420|\\#SRR2473222|214_461_27|\n",
    "|33507|\\#SRR2473223|214_461_28|\n",
    "|55574|\\#SRR2473224|214_461_29|\n",
    "|33877|\\#SRR2473338|214_461_46|\n",
    "\n",
    "_Count of all variants in file and of variants that passed the filter are printed to stdout_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\tpassed\n",
      "7012855\t1785832\n"
     ]
    }
   ],
   "source": [
    "vcfFile = vcf.Reader( open('merged_annot.vcf','r') )\n",
    "outfile = vcf.Writer(open('merged_annot_filter1.vcf', 'w'), vcfFile)\n",
    "\n",
    "miceIDs=['214_461_27','214_461_28','214_461_29','214_461_46']\n",
    "\n",
    "#filters statistics\n",
    "counter=0\n",
    "passed=0\n",
    "\n",
    "for record in vcfFile:  \n",
    "    counter+=1    \n",
    "    #count how many MF5L6 mice share the called variant\n",
    "    count_hets=0\n",
    "    for i in miceIDs:\n",
    "        if not record.genotype(i)==None and not record.genotype(i)['GT']==None:\n",
    "            if record.genotype(i)['GT']=='0/1':\n",
    "                count_hets+=1\n",
    "                \n",
    "    #remove variants where none of the MF5L6 mice is heterozygous\n",
    "    if count_hets==0:\n",
    "        continue\n",
    "\n",
    "    passed+=1\n",
    "    outfile.write_record(record)\n",
    "    \n",
    "#print filters statistics    \n",
    "print('all','passed',sep='\\t')   \n",
    "print(counter,passed,sep='\\t')\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###FILTER 2\n",
    "from 'merged_annot_filter1.vcf' to 'merged_annot_filter2.vcf'\n",
    "\n",
    "This step will apply multiple quality filters to identify likely ENU induced mutations in *MF5L*6 mice. In order to pass the filters, the variant has to be:\n",
    "- heterozygous only in *MF5L*6 mice compared to other sequenced in-house mice\n",
    "- called in at least 50% of the mice (17) to be able to assess uniqueness\n",
    "- have at least a read debth of 6 and an allele ratio between 1/2 and 2 for reads DB\\<=10 and between 1/3 and 3 for DB\\>10\n",
    "- not present in the list of known C57BL/6J and 129/SvImJ SNPs\n",
    "\n",
    "_Count of all variants entering this step, of variants removed by each filter, and of variants that passed all filters are printed to stdout_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\tshared\t<50%GT\tbadDP\t129var\tpassed\n",
      "1785832\t1681696\t46669\t51224\t6\t6237\n"
     ]
    }
   ],
   "source": [
    "vcfFile = vcf.Reader( open('merged_annot_filter1.vcf','r') )\n",
    "outfile = vcf.Writer(open('merged_annot_filter2.vcf', 'w'), vcfFile)\n",
    "\n",
    "miceIDs=['214_461_27','214_461_28','214_461_29','214_461_46']\n",
    "\n",
    "#filters statistics\n",
    "counter=0\n",
    "(f1,f2,f3,f4,passed)=(0,0,0,0,0)\n",
    "\n",
    "for record in vcfFile:  \n",
    "    counter+=1    \n",
    "    \n",
    "    #count how many MF5L6 mice share the called heterozygous variant\n",
    "    count_hets=0\n",
    "    for i in miceIDs:\n",
    "        if not record.genotype(i)==None and not record.genotype(i)['GT']==None:\n",
    "            if record.genotype(i)['GT']=='0/1':\n",
    "                count_hets+=1\n",
    "                \n",
    "    #remove variants where other mice shared the same variant allele as het or alt-hom    \n",
    "    if record.num_het>count_hets or record.num_hom_alt>0:\n",
    "        f1+=1\n",
    "        continue\n",
    "        \n",
    "    #remove variants where >50% of the mice (17 mice) have no genotype called     \n",
    "    if record.num_unknown>=17:\n",
    "        f2+=1\n",
    "        continue \n",
    "\n",
    "    #called variant should have read depth of 6 at least in one of 4 mice\n",
    "    #with allele ratios between 1/2 and 2 or 1/3 and 3:\n",
    "    count_DP=0\n",
    "    for i in miceIDs:\n",
    "        if not record.genotype(i)==None and not record.genotype(i)['DP']==None:\n",
    "            if int(record.genotype(i)['DP'])>=6:\n",
    "                ref=float(record.genotype(i)['AD'][0])\n",
    "                alt=float(record.genotype(i)['AD'][1])\n",
    "                dev=alt/ref\n",
    "                if alt==0 or ref==0:\n",
    "                    continue \n",
    "                if int(record.genotype(i)['DP'])<=10:\n",
    "                    if dev<0.5 or dev>2:\n",
    "                        continue\n",
    "                if int(record.genotype(i)['DP'])>10:\n",
    "                    if dev<0.333 or dev>3:\n",
    "                        continue\n",
    "                count_DP+=1\n",
    "                \n",
    "    if count_DP==0:\n",
    "        f3+=1\n",
    "        continue\n",
    "    \n",
    "    #remove all variants overlapping with known C57BL/6J and 129S1/SvIMJ SNPs \n",
    "    if str(record.CHROM)+'_'+str(record.POS) in IMJ:\n",
    "        f4+=1\n",
    "        continue\n",
    "        \n",
    "    passed+=1\n",
    "    outfile.write_record(record)\n",
    "#print filters statistics   \n",
    "print('all','shared','<50%GT','badDP','129var','passed',sep='\\t')   \n",
    "print(counter,f1,f2,f3,f4,passed,sep='\\t')\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###FILTER 3\n",
    "from 'merged_annot_filter2.vcf' to 'merged_annot_filter3.vcf'\n",
    "\n",
    "This filter will remove variants that are <=200bp apart. Closely called variants are mostly not of ENU origin but false positives do to misalignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RemoveVariantsWithin200bp(FileName,OutFile):\n",
    "    '''Removes variants that are closer than 200 bp to each other'''\n",
    "    \n",
    "    input=open(FileName)\n",
    "    outfile=open(OutFile,'w')\n",
    "    \n",
    "    header=input.readline().rstrip()\n",
    "    print(header,file=outfile)\n",
    "\n",
    "    chr=''\n",
    "    pos=0\n",
    "    removed_pos=0\n",
    "    rows=[]\n",
    "    counter=0\n",
    "    passed=0\n",
    "\n",
    "    for line in input:\n",
    "        counter+=1\n",
    "        line=line.rstrip()\n",
    "        row=line.split('\\t')\n",
    "        if not row[0]==chr:\n",
    "            chr=row[0]\n",
    "            pos=int(row[1])\n",
    "            rows.append(line)\n",
    "            removed_pos=0\n",
    "            continue\n",
    "        else:\n",
    "            if int(row[1])-removed_pos <= 200:\n",
    "                    removed_pos=int(row[1])\n",
    "                    continue\n",
    "            else:\n",
    "                if int(row[1])-pos <= 200:\n",
    "                    rows.pop()\n",
    "                    removed_pos=int(row[1])\n",
    "                    continue\n",
    "                else:\n",
    "                    pos=int(row[1])\n",
    "                    rows.append(line)\n",
    "                    continue\n",
    "\n",
    "    for line in rows:\n",
    "        passed+=1\n",
    "        print(line,file=outfile)\n",
    "\n",
    "    #for stats, this is the number of all and discarded variants\n",
    "    print('all','passed',sep='\\t')   \n",
    "    print(counter,passed,sep='\\t')\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\tpassed\n",
      "6237\t5946\n"
     ]
    }
   ],
   "source": [
    "RemoveVariantsWithin200bp('merged_annot_filter2.vcf','merged_annot_filter3.vcf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###FILTER 4\n",
    "from 'merged_annot_filter3.vcf' to 'merged_annot_filter4.vcf'\n",
    "\n",
    "This filter removes variants present in only 1 out of 4 *MF5L6* mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\tpassed\n",
      "5946\t94\n"
     ]
    }
   ],
   "source": [
    "vcfFile = vcf.Reader( open('merged_annot_filter3.vcf','r') )\n",
    "outfile = vcf.Writer(open('merged_annot_filter4.vcf', 'w'), vcfFile)\n",
    "\n",
    "miceIDs=['214_461_27','214_461_28','214_461_29','214_461_46']\n",
    "\n",
    "#filters statistics\n",
    "counter=0\n",
    "passed=0\n",
    "\n",
    "for record in vcfFile:  \n",
    "    counter+=1    \n",
    "    \n",
    "    #count how many MF5L6 mice share the called variant\n",
    "    count_hets=0\n",
    "    for i in miceIDs:\n",
    "        if not record.genotype(i)==None and not record.genotype(i)['GT']==None:\n",
    "            if record.genotype(i)['GT']=='0/1':\n",
    "                count_hets+=1\n",
    "                \n",
    "    #remove variants present in only 1 mouse:    \n",
    "    if count_hets<2:\n",
    "        continue\n",
    "    else:\n",
    "        passed+=1\n",
    "        outfile.write_record(record)\n",
    "        \n",
    "#print filters statistics    \n",
    "print('all','passed',sep='\\t')   \n",
    "print(counter,passed,sep='\\t')\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Summary statistics\n",
    "\n",
    "Pull out summary statistics on variant types from three different stages of filtering (for Table 1 in *NBEAL2* manuscript):\n",
    "- all variants in *MF5L*6 ('merged_annot_filter1.vcf')\n",
    "- unique heterozygous variants in *MF5L*6 ('merged_annot_filter3.vcf')\n",
    "- unique heterozygous variants shared by more than 1 *MF5L*6 mouse ('merged_annot_filter4.vcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'COMPLEX': 2, 'INSERTION': 117963, 'MULTIALLELIC_COMPLEX': 11061, 'MULTIALLELIC_SNP': 517, 'DELETION': 190667, 'SNP': 1465622}\n"
     ]
    }
   ],
   "source": [
    "#get a sense of what type of VariantType's are in the data set\n",
    "input=open('merged_annot_filter1.vcf')\n",
    "\n",
    "var=dict()\n",
    "\n",
    "for line in input:\n",
    "    if line.startswith('#'):\n",
    "        continue\n",
    "    row=line.rstrip().split('\\t')\n",
    "    for i in row[7].split(';'):\n",
    "        if i.startswith('VariantType='):\n",
    "            data=i.split('VariantType=')[1].split('.')[0]\n",
    "    if data in var:\n",
    "        var[data]+=1\n",
    "    else:\n",
    "        var[data]=1\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summary stats on INDELs and SNPs for unique variants in Line 6 mice\n",
    "def SummaryStatsOfVariantType(FileName):\n",
    "    '''This generator separates SNPs and INDELs in the file\n",
    "    and counts up their Annotation Types based on Annovar data added to INFO'''\n",
    "\n",
    "    input=open(FileName)\n",
    "\n",
    "    type_snp=dict()\n",
    "    type_indel=dict()\n",
    "\n",
    "    for line in input:\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        variant='COMPLEX'\n",
    "        type=''\n",
    "        row=line.rstrip().split('\\t')\n",
    "        for i in row[7].split(';'):\n",
    "            if i.startswith('VariantType='):\n",
    "                data=i.split('VariantType=')[1].split('.')[0]\n",
    "                if data.startswith('DELETION') or data.startswith('INSERTION'):\n",
    "                    variant='INDEL'\n",
    "                if data.startswith('SNP') or data.startswith('MULTIALLELIC_SNP'):\n",
    "                    variant='SNP'\n",
    "            if i.startswith('AnnovarType='):\n",
    "                type=i.split('=')[1]\n",
    "\n",
    "        if variant=='SNP':\n",
    "            if not type in type_snp:\n",
    "                type_snp[type]=1\n",
    "            else:\n",
    "                type_snp[type]+=1\n",
    "        elif variant=='INDEL':\n",
    "            if not type in type_indel:\n",
    "                type_indel[type]=1\n",
    "            else:\n",
    "                type_indel[type]+=1\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    print('SNP data:\\n')\n",
    "    for i in type_snp:\n",
    "        print(i,type_snp[i])\n",
    "    print('\\nINDEL data:\\n')\n",
    "    for i in type_indel:\n",
    "        print(i,type_indel[i])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNP data:\n",
      "\n",
      "splicing 63\n",
      "stoploss 21\n",
      "ncRNA_splicing 27\n",
      "downstream 16289\n",
      "UTR5 5164\n",
      "ncRNA_exonic 3788\n",
      "intergenic 734219\n",
      "intronic 597007\n",
      "unknown 247\n",
      "UTR3 25336\n",
      "stopgain 87\n",
      "synonymous_SNV 21130\n",
      "upstream 17717\n",
      "nonsynonymous_SNV 11854\n",
      "ncRNA_intronic 33190\n",
      "\n",
      "INDEL data:\n",
      "\n",
      "nonframeshift_insertion 187\n",
      "frameshift_insertion 117\n",
      "stoploss 1\n",
      "downstream 4211\n",
      "splicing 68\n",
      "UTR5 912\n",
      "ncRNA_exonic 592\n",
      "intergenic 144695\n",
      "intronic 138566\n",
      "unknown 18\n",
      "UTR3 7122\n",
      "stopgain 4\n",
      "ncRNA_splicing 3\n",
      "upstream 4426\n",
      "nonframeshift_deletion 273\n",
      "frameshift_deletion 227\n",
      "ncRNA_intronic 7208\n"
     ]
    }
   ],
   "source": [
    "SummaryStatsOfVariantType('merged_annot_filter1.vcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNP data:\n",
      "\n",
      "splicing 2\n",
      "stoploss 1\n",
      "downstream 66\n",
      "UTR5 6\n",
      "ncRNA_exonic 19\n",
      "intergenic 2849\n",
      "intronic 2399\n",
      "UTR3 92\n",
      "stopgain 3\n",
      "synonymous_SNV 27\n",
      "upstream 54\n",
      "nonsynonymous_SNV 66\n",
      "ncRNA_intronic 149\n",
      "\n",
      "INDEL data:\n",
      "\n",
      "splicing 1\n",
      "downstream 1\n",
      "UTR5 1\n",
      "intergenic 92\n",
      "intronic 103\n",
      "UTR3 3\n",
      "upstream 3\n",
      "frameshift_deletion 3\n",
      "ncRNA_intronic 6\n"
     ]
    }
   ],
   "source": [
    "SummaryStatsOfVariantType('merged_annot_filter3.vcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNP data:\n",
      "\n",
      "intergenic 32\n",
      "intronic 35\n",
      "UTR3 3\n",
      "stopgain 1\n",
      "synonymous_SNV 2\n",
      "nonsynonymous_SNV 6\n",
      "ncRNA_intronic 2\n",
      "\n",
      "INDEL data:\n",
      "\n",
      "intergenic 5\n",
      "intronic 6\n",
      "frameshift_deletion 1\n",
      "ncRNA_intronic 1\n"
     ]
    }
   ],
   "source": [
    "SummaryStatsOfVariantType('merged_annot_filter4.vcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
